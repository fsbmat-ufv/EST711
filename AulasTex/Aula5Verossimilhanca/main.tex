\documentclass[12pt]{beamer}

\input{../Configuracoes/layout}

\title{Inferência Estatística II}
\author{Prof. Fernando de Souza Bastos\texorpdfstring{\\ fernando.bastos@ufv.br}{}}
\institute{Departamento de Estatística\texorpdfstring{\\ Programa de Pós-Graduação em Estatística Aplicada e Biometria}\texorpdfstring{\\ Universidade Federal de Viçosa}{}\texorpdfstring{\\ Campus UFV - Viçosa}{}}
\date{}
\newcommand\mytext{Aula 5}
\newcommand\mytextt{Fernando de Souza Bastos}
\newcommand\mytexttt{\url{https://est711.github.io/}}


\begin{document}
%\SweaveOpts{concordance=TRUE}

\frame{\titlepage}

\begin{frame}{}
\frametitle{\bf Sumário}
\tableofcontents
\end{frame}

\section{Método dos Momentos}
\begin{frame}{Introdução ao Método dos Momentos}
    \begin{block}{}
    \justifying
O método dos momentos é uma técnica desenvolvida pelo matemático e estatístico Karl Pearson no final do século XIX.
\end{block}
\pause
\begin{block}{}
    \justifying
É amplamente aplicado em áreas como Engenharia, Ciências Sociais e Biológicas, dentre outras. É um dos mais simples e intuitivos métodos de inferência estatística, e pode ser facilmente adaptado a diferentes distribuições de probabilidade, o que o torna uma ferramenta útil na análise de dados.
\end{block}
\end{frame}

\begin{frame}{Método dos Momentos}
\vspace{-0.1cm}
\begin{block}{}
\justifying
O método dos momentos consiste em igualar os momentos amostrais de uma distribuição teórica com os momentos correspondentes da distribuição amostral, e estimar os parâmetros da distribuição teórica a partir desses momentos.
\end{block}
\pause
\vspace{-0.1cm}
\begin{block}{}
    Seja 
    \begin{align}
        m_{r}=\dfrac{1}{n}\displaystyle{\sum_{i=1}^{n}X_{i}^{r}},~r\geq 1
    \end{align}
o $r-$ésimo momento amostral de uma amostra aleatória $X_1, \dots, X_n.$ Seja, 
    \begin{align}
        \mu_{r}=E(X^{r}),~r\geq 1
    \end{align}
    o $r-$ésimo momento populacional.
\end{block}
\end{frame}

\begin{frame}{}
    \begin{block}{}
    \justifying
O método dos momentos consiste na obtenção de estimadores para $\theta=(\theta_{1}, \dots, \theta_{k}),$ resolvendo as equações 
\begin{align}
        m_{r}&=\mu_{r},~r=1,\dots,k.\\
        \frac{1}{n} \sum_{i=1}^{n} X_i^r &= E(X^{r})
    \end{align}


onde $X_1, X_2, ..., X_n$ são as observações amostrais, $\mu_r$ é o r-ésimo momento teórico da distribuição, e $n$ é o tamanho da amostra. A partir dessa equação, é possível obter estimativas dos parâmetros da distribuição teórica por meio da solução de um sistema de equações, em que as equações correspondem aos primeiros momentos até a ordem $k$ da distribuição.
\end{block}
\end{frame}

\begin{frame}{Exemplo 1}
\begin{block}{}
\justifying
Suponha que \(X_1, X_2, \ldots, X_n\) sejam variáveis aleatórias independentes e identicamente distribuídas (iid) com distribuição \(N(\theta, \sigma^2)\). Temos \(m_1 = \bar{X}\), \(m_2 = {\displaystyle \frac{1}{n} \sum_{i=1}^{n} X_i^2}\), \(\mu_1' = \theta\), \(\mu_2' = \theta^{2}+\sigma^2\), e, portanto, devemos resolver
\begin{align*}
\bar{X} = \theta~\text{e}~{\displaystyle \frac{1}{n} \sum_{i=1}^{n} X_i^2} = \theta^{2}+\sigma^2.
\end{align*}

Resolvendo para \(\theta\) e \(\sigma^2\), obtemos os estimadores pelo método de momentos:
\begin{align*}
\theta = \bar{X}~\text{e}~{\displaystyle \frac{1}{n} \sum_{i=1}^{n}X_{i}^{2}=\theta^{2}+\sigma^{2}}=\bar{X}^{2}+\sigma^{2}\Rightarrow \sigma^2 &= \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X})^2.
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{}
\justifying
Sejam \(X_1, \ldots, X_n\) uma amostra aleatória da distribuição de \(X\), com densidade gama de parâmetros \(\alpha\) e \(\beta\) dada por
\[
f(x) = \frac{\beta^\alpha x^{\alpha-1} e^{-\beta x}}{\Gamma(\alpha)}, \quad x > 0, \alpha > 0, \beta > 0.
\]
Sabendo que
\[
E[X] = \frac{\alpha}{\beta} \quad \text{e} \quad \text{Var}[X] = \frac{\alpha}{\beta^2},
\]
obtemos que os estimadores para \(\alpha\) e \(\beta\) são obtidos como solução das equações
\begin{align*}
\dfrac{\hat{\alpha}}{\hat{\beta}}=\dfrac{1}{n}{\displaystyle \sum_{i=1}^{n}X_{i}}~\text{e}~\dfrac{\hat{\alpha}^{2}}{\hat{\beta}^{2}}+\dfrac{\hat{\alpha}}{\hat{\beta}^{2}}=\dfrac{1}{n}{\displaystyle \sum_{i=1}^{n}X_{i}^{2}}
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{}
\justifying
Logo,
\begin{align*}
\dfrac{\hat{\alpha}}{\hat{\beta}}=\bar{X}&\Rightarrow \hat{\alpha}=\hat{\beta}\bar{X}\Rightarrow \hat{\alpha}^{2}=\hat{\beta}^{2}\bar{X}^{2}\\ &\Rightarrow \dfrac{1}{n}{\displaystyle \sum_{i=1}^{n}X_{i}^{2}}=\dfrac{\hat{\alpha}^{2}+\hat{\alpha}}{\hat{\beta}^{2}}=\dfrac{\hat{\beta}^{2}\bar{X}^{2}+\hat{\beta}\bar{X}}{\hat{\beta}^{2}}=\dfrac{\hat{\beta}\bar{X}^{2}+\bar{X}}{\hat{\beta}}\\
&\Rightarrow \dfrac{1}{n}{\displaystyle \sum_{i=1}^{n}X_{i}^{2}}=\dfrac{\bar{X}}{\hat{\beta}}+\bar{X}^{2}\Rightarrow \hat{\beta}=\dfrac{\Bar{X}}{\dfrac{1}{n}{\displaystyle \sum_{i=1}^{n}X_{i}^{2}}-\Bar{X}^{2}}=\dfrac{\bar{X}}{\hat{\sigma}^{2}}\\
&\Rightarrow \hat{\alpha}=\dfrac{\bar{X}^{2}}{\hat{\sigma}^{2}},~\text{em que}~\hat{\sigma}^{2}=\dfrac{1}{n}{\displaystyle \sum_{i=0}^{n}(X_{i}-\bar{X})^{2}}
\end{align*}
\end{block}
\end{frame}

\section{Método da Máxima Verossimilhança}
\begin{frame}{Introdução ao Método da Máxima Verossimilhança}
    \begin{block}{}
    \justifying
O método de estimação por Máxima Verossimilhança foi criado pelo estatístico britânico Ronald A. Fisher em 1912. Sua finalidade é estimar os valores desconhecidos dos parâmetros de um modelo estatístico com base em dados observados, maximizando a verossimilhança dos dados. Isso significa encontrar os valores dos parâmetros que tornam os dados observados mais prováveis de terem sido gerados pelo modelo proposto. 
\end{block}
\end{frame}

\begin{frame}{}
    \begin{block}{}
    \justifying
As vantagens do método incluem sua simplicidade e robustez, bem como sua ampla aplicabilidade em diversas áreas da ciência, desde a física e a biologia até a economia e as ciências sociais. Além disso, o método de máxima verossimilhança é frequentemente utilizado como base para métodos mais avançados de inferência estatística, como a análise de variância e a regressão linear.
\end{block}
\end{frame}

\begin{frame}{}
    \begin{block}{O que é Verossimilhança dos dados?}
    \justifying
A verossimilhança dos dados é uma medida de quão provável é um determinado conjunto de dados ter sido gerado por um modelo estatístico específico. Em outras palavras, a verossimilhança representa a probabilidade de se obter os dados observados, dada uma hipótese sobre os parâmetros desconhecidos do modelo. Quanto maior a verossimilhança, mais provável é que os dados tenham sido gerados pelo modelo em questão. A estimação dos parâmetros do modelo por máxima verossimilhança envolve a busca pelos valores dos parâmetros que maximizam a verossimilhança dos dados.
\end{block}
\end{frame}

\begin{frame}{Definições Importantes}
\begin{definicao}\label{def5}
    Dada uma amostra $X_1, X_2, ..., X_n$ iid de uma população com fdp ou fp $f(x,\theta),$ em que $\theta$ é um parâmetro desconhecido. A base para nossos procedimentos inferenciais será a função de verossimilhança definida por:
    \begin{align}\label{vero1}
    L(\theta)=\displaystyle{\prod_{i=1}^{n}f(x_{i},\theta)},
    \end{align}
Em que, $x_{i}$ é o valor observado de $X_{i},~i=1,\ldots, n.$
\end{definicao}
\end{frame}

\begin{frame}{Log-Verossimilhança}
\begin{block}{}
\justifying
O logaritmo da função $(\ref{vero1})$ é mais tratável matematicamente. Trabalharemos então com ele, que é conhecido como log-verossimilhança.
\begin{align*}
    \ell(\theta)=\log{L(\theta)}=\Sumi \log{f(x_{i},\theta)},\theta\in \Omega
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Exemplo}
\begin{block}{}
\justifying
Sejam $X_1, X_2, ..., X_n$ uma amostra aleatória de uma distribuição com função de probabilidade
\begin{align*}
    P(x)=\theta^{x}(1-\theta)^{1-x},~x\in\{0,1\}~\text{e}~\theta\in[0,1].
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
A função de verossimilhança é dada por:
\begin{align*}
    L(\theta)={\displaystyle \Prodi P(X_{i}=x_{i})=\Prodi \theta^{x_{i}}(1-\theta)^{1-x_{i}}}=\theta^{\sum x_{i}}(1-\theta)^{n-\sum x_{i}}.
\end{align*}
\end{block}
\pause
\begin{block}{}
	Veja o gráfico de verossimilhança,  \href{https://est711.shinyapps.io/Verossimilhanca/}{cliquem aqui!} 
\end{block}
\end{frame}

\begin{frame}{}
    \begin{block}{}
    \justifying
O valor de $\theta$ que maximiza a função anterior é um bom estimador para $\theta.$ Ele dá a maior probabilidade para a amostra observada. Neste caso a função log-verossimilhança é dada por:
\begin{align*}
\ell(\theta)&=\Sumi x_{i}\log{\theta}+(n-\Sumi x_{i})\log{(1-\theta)}\\
\Rightarrow \dfrac{\partial\ell(\theta)}{\partial\theta}&=\dfrac{\Sumi x_{i}}{\theta}-\dfrac{n-\Sumi x_{i}}{1-\theta}
\end{align*}
Para achar o ponto crítico, igualamos a derivada a zero, ou seja:
\begin{align*}
\dfrac{\partial\ell(\theta)}{\partial\theta}=0&\Rightarrow \hat{\theta}=\dfrac{\Sumi x_{i}}{n}
\end{align*}
é o estimador de máxima verossimilhança de $\theta.$
\end{block}

\end{frame}

\begin{frame}{Condições de Regularidade}
\begin{block}{}
\justifying
Seja $\theta_{0}$ o valor verdadeiro de $\theta.$ O próximo teorema nos dá uma justificativa teórica para maximar a função de verossimilhança. Para isso assumiremos algumas condições de regularidade. 
\begin{description}
\item[(R0)~] Se $\theta\neq \theta^{'},$ então $f(x,\theta)\neq f(x,\theta^{'}).$
\item[(R1)~] As densidades possuem o mesmo suporte para todo $\theta,$ ou seja, o suporte não pode depender do parâmetro.
\item[(R2)~] O ponto $\theta_{0}$ é um ponto interior de $\Omega,$ em que $\Omega$ é o suporte da função densidade.
\end{description}
\end{block}
\end{frame}

\begin{frame}{Teorema}
\begin{Teorema}\label{Teo1}
\justifying
Seja $\theta_{0}$ o valor verdadeiro de $\theta.$ Sob $(R0)$ e $(R1),$ temos que
\begin{align*}
    \Lim P_{\theta_{0}}(L(\theta_{0},X)>L(\theta,X))=1,~\text{para}~\theta\neq \theta_{0},
\end{align*}
ou seja, $\theta_{0}$ é o ponto de máximo de $L(\theta,X).$
\end{Teorema}
\end{frame}

\begin{frame}{Demonstração}
\begin{block}{}
\justifying
\begin{align*}
L(\theta_{0},X)>L(\theta,X)&\Leftrightarrow {\displaystyle \Prodi f(x_{i},\theta_{0})>\Prodi f(x_{i},\theta)}\\
&\Leftrightarrow\Sumi\log{f(x_{i},\theta_{0})}>\Sumi\log{f(x_{i},\theta)}\\
&\Leftrightarrow\Sumi\log{\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)}<0\\
&\Leftrightarrow\dfrac{1}{n}\Sumi\log{\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)}<0
\end{align*}
Seja $y_{i}=\log{\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)},~i=1,\ldots,n.$
\end{block}
\end{frame}

\begin{frame}{Continuação da Demonstração}
\begin{block}{}
\justifying
$Y_{1},\ldots,Y_{n}$ é uma sequência de v.a. iid com média finita. Pela lei fraca dos grandes números
\begin{align*}
    \dfrac{\Sumi y_{i}}{n}\ConvP E_{\theta_{0}}(Y_{i})=E\Big[\log{\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)}\Big]\\
    \SetaUP{\text{Desigualdade de Jensen}}{<}\log{E_{\theta_{0}}\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)}
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Continuação da Demonstração}
\begin{block}{}
\justifying
Note que,
\begin{align*}
E_{\theta_{0}}\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)&\SetaUP{f~\text{de}~\theta~\text{e}~f~\text{de}~\theta_{0}~\text{tem o mesmo suporte}}{=}\int_{\R} \dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}f(x,\theta_{0})dx=1\\
&\Rightarrow \dfrac{\Sumi y_{i}}{n}<0~\text{para}~n\rightarrow +\infty\\
&\Rightarrow \dfrac{1}{n}\Sumi\log{\Big(\dfrac{f(x_{i},\theta)}{f(x_{i},\theta_{0})}\Big)}~\text{converge em probabilidade}
\end{align*}
para uma constante negativa. Assim, $L(\theta_{0},X)>L(\theta,X)$ para $\theta\neq\theta_{0}.$
\end{block}
\end{frame}

\begin{frame}{Estimador de Máxima Verossimilhança}
\begin{definicao}\label{def6}
Dizemos que $\hat{\theta}=\hat{\theta}(x)$ é um Estimador de Máxima Verossimilhança (EMV) de $\theta$ se  $$\hat{\theta}=argmax_{\theta} L(\theta,\boldsymbol{X}), \hat{\theta}\in \Theta.$$
\end{definicao}
\end{frame}

\begin{frame}{Exemplo}
\begin{block}{}
\justifying
Sejam $X_{1},\ldots,X_{n}\Sim \exp{(\theta)},$ 
\begin{align*}
    f(x)=\dfrac{1}{\theta}e^{-\frac{x}{\theta}},x>0,\theta>0
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
A log-verossimilhança fica dada por 
\begin{align*}
    \ell(\theta)&=-n\log{\theta}-\theta^{-1}\Sumi x_{i}\\
    \Rightarrow \hat{\theta}&=\Bar{X}
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Exemplo}
\vspace{-0.3cm}
\begin{block}{}
\justifying
Sejam $X_{1},\ldots,X_{n}\Sim U(0,\theta],$ 
\begin{align*}
    f(x)=\dfrac{1}{\theta},x\in(0,\theta],\theta>0
\end{align*}
\end{block}
\pause
\begin{block}{\Home}
\justifying
\begin{align*}
L(\theta)=\Prodi f(x_{i},\theta)&=\Prodi\dfrac{1}{\theta}\delta(0,\theta],~\delta(0,\theta]=\begin{cases}
			1, & \text{se $x_{i}\in(0,\theta]$}\\
            0, & \text{c.c}
		 \end{cases}\\
   &=\Big(\dfrac{1}{\theta}\Big)^{n}\delta\{max(x_{1},\ldots,x_{n})\leq \theta\}
\end{align*}
Mostre que $\hat{\theta}=max(X_{1},\ldots,X_{n})$
\end{block}
\end{frame}

%\begin{frame}{}
%\begin{definicao}\label{def6}
%    O estimador de Máxima Verossimilhança (EMV) de $\theta$ é o valor $\hat{\theta}\in \Theta$ que maximiza a função de verossimilhança $L(\theta|\boldsymbol{x}).$
%\end{definicao}
%\begin{block}{}
%    \justifying
%O logaritmo natural da função de verossimilhança de $\theta$ é denotado por 
%\begin{align*}
%    \ell(\theta)=\log{L(\theta;\boldsymbol{x})}.
%\end{align*}
%\end{block}
%\begin{block}{}
%    \justifying
%Não é difícil verificar que o valor de $\theta$ que maximiza a função de verossimilhança $L(\theta; \boldsymbol{x}),$ também maximiza $\ell(\theta; \boldsymbol{x})$. Além disso, no caso uniparamétrico onde $\Theta$ é um intervalo da reta e $\ell(\theta; \boldsymbol{x})$ é derivável, o estimador de máxima verossimilhança pode ser encontrado como a raiz da equação de verossimilhança
%\begin{align}\label{eq11}
%    \ell^{'}(\theta;\boldsymbol{x})=\dfrac{\partial \ell(\theta;\boldsymbol{x})}{\partial \theta}=0.
%\end{align}
%\end{block}
%\end{frame}

\begin{frame}{}
    \begin{block}{}
    \justifying
Em alguns exemplos simples, a solução da equação de verossimilhança pode ser obtida explicitamente. Em situações mais complicadas, a solução da equação (\ref{eq1}) será em geral obtida por procedimentos numéricos. Para se concluir que a solução da equação (\ref{eq1}) é um ponto de máximo, é necessário verificar se:
\begin{align}\label{eq1}
    \ell^{''}(\hat{\theta};\boldsymbol{x})=\dfrac{\partial^{2} \ell(\theta;\boldsymbol{x})}{\partial^{2} \theta}\at{\theta=\hat{\theta}}<0.
\end{align}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Encontrar o EMV pode ser um problema complexo em alguns casos, devido a várias dificuldades, incluindo:

\begin{itemize}
\justifying
    \item \textbf{Função de verossimilhança complexa:} Em muitos casos, a função de verossimilhança é complexa e não possui uma forma analítica simples. Isso pode tornar a maximização da função de verossimilhança um problema difícil e pode exigir o uso de técnicas computacionais sofisticadas.\pause

    \item \textbf{Convergência:} O EMV é encontrado pela maximização da função de verossimilhança. Em alguns casos, a função de verossimilhança pode ter várias máximas locais, o que pode dificultar a convergência do algoritmo de otimização para a solução global. Isso pode ser especialmente problemático se a função de verossimilhança for multimodal e as várias máximas locais estiverem próximas em termos de valor.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\begin{itemize}
\justifying
    \item \textbf{Dados insuficientes:} Em alguns casos, a quantidade de dados disponíveis pode não ser suficiente para permitir uma estimativa precisa dos parâmetros do modelo. Isso pode tornar a estimativa do EMV imprecisa e pode resultar em intervalos de confiança amplos ou em estimativas enviesadas.\pause

    \item \textbf{Modelos mal especificados:} O EMV é um método que depende da escolha do modelo estatístico correto. Se o modelo estiver mal especificado, o EMV pode levar a estimativas imprecisas ou enviesadas dos parâmetros do modelo.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}

\begin{itemize}
\justifying
\item \textbf{Computacionalmente caro:} Em alguns casos, a computação do EMV pode ser computacionalmente cara, especialmente se a função de verossimilhança for complexa e exigir muitos cálculos. Isso pode tornar o EMV impraticável em alguns casos.
\end{itemize}
\end{block}
\pause
\begin{block}{}
\justifying
Em resumo, o EMV pode ser difícil de encontrar em algumas situações, especialmente quando a função de verossimilhança é complexa, a convergência é difícil, os dados são insuficientes, o modelo está mal especificado ou a computação é cara. No entanto, em muitos casos, o EMV é um método poderoso e útil para estimar os parâmetros do modelo.
\end{block}
\end{frame}

\begin{frame}{Exemplo 1}
\begin{block}{Verossimilhança da Normal}
\justifying
Sejam \seqX $~N(\theta,1)$ iid e $L(\theta|\boldsymbol{x})$ denota a função de verossimilhança. Então,
\begin{align*}
    L(\theta|\boldsymbol{x})=\Prodi \dfrac{1}{(2\pi)^{\frac{1}{2}}}e^{-(1/2)(x_{i}-\theta)^{2}}=\dfrac{1}{(2\pi)^{\frac{n}{2}}}e^{-(1/2)\Sumi(x_{i}-\theta)^{2}}.
\end{align*}
A equação $\dfrac{d}{d\theta}L(\theta|\boldsymbol{x})=0$ se reduz para 
\begin{align*}
    \Sumi(x_{i}-\theta)=0
\end{align*}
que tem solução $\hat{\theta}=\bar{x}$
\end{block}
\end{frame}

\begin{frame}{Exemplo 1}
\begin{block}{Verossimilhança da Normal}
\justifying
Assim, $\bar{x}$ é um candidato para o EMV. Para verificar que $\bar{x}$ é um máximo global, observamos que ele é a única solução para $\Sumi(x_{i}-\theta)=0.$ Além disso, é possível observar que 
\begin{align*}
    \dfrac{d^{2}}{d\theta^{2}}L(\theta|\boldsymbol{x})|_{\theta=\bar{x}}<0
\end{align*}
e que ${\displaystyle \lim_{\theta\to\pm\infty}}L(\theta|\boldsymbol{x})=0.$ Logo, $\bar{x}$ é um máximo global, isto é, $\bar{x}$ é o EMV de $\theta$.
\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{EMV de Bernoulli}
\justifying
Sejam \seqX~ Bernoulli$(p)$ iid. Então, a função de verossimilhança é,
\begin{align*}
    L(p|\boldsymbol{x})=\Prodi p^{x_{i}}(1-p)^{1-x_{i}}=p^{y}(1-p)^{n-y},~\text{em que},~y=\Sumi x_{i}.
\end{align*}
Considere o log de verossimilhança dado por,
\begin{align*}
    \ell(p|\boldsymbol{x})=\log{L(p|\boldsymbol{x})}=y\log{p}+(n-y)\log{(1-p)}.
\end{align*}
\end{block}
\pause
\begin{block}{EMV de Bernoulli}
\justifying
Se $0<y<n,$ diferenciar $\log{L(p|\boldsymbol{x})}$ e igualar o resultado a zero fornece a solução $\hat{p}=\dfrac{y}{n}.$ 
\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{EMV de Bernoulli}
\justifying
É fácil verificar que $\hat{p}=\dfrac{y}{n}$ é máximo global, pois se $y=0$ ou $y=n,$ temos
\begin{align*}
\log{L(p|\boldsymbol{x})}=
\begin{cases}
      n\log{(1-p)},&\text{se}~y=0\\
      n\log{p},&\text{se}~y=n
    \end{cases}\,.
\end{align*}
Em qualquer um dos casos temos $\log{L(p|\boldsymbol{x})}$ é uma função monótona de $p$ e, portanto, $\hat{p}=\dfrac{y}{n}$ é ponto de máximo. Assim, $\hat{p}=\dfrac{y}{n}$ é o EMV de $p.$
\end{block}
\end{frame}

\begin{frame}{Princípio da Invariância dos EMV}
\begin{Teorema}\label{Teo2}
\justifying
Seja $X_1, X_2, ..., X_n$ uma a.a. de uma distribuição com densidade $f(\boldsymbol{x};\theta), \theta \in \Theta.$ Seja $g$ uma função especificada e $\eta=g(\theta).$ Suponha $\hat{\theta}$ o EMV de $\theta$, então $\hat{\eta}=g(\hat{\theta})$ é o EMV de $\eta.$
\end{Teorema}
\end{frame}

\begin{frame}{Princípio da Invariância dos EMV}
\begin{block}{}
\justifying
Em outras palavras, se estamos interessados em estimar alguma quantidade de interesse (\(\eta\)) que pode ser expressa como uma função dos parâmetros (\(\theta\)) da distribuição, pode ser, por exemplo, uma transformação do parâmetro $\theta$, como o quadrado, o logaritmo, ou qualquer outra função. Basta, simplesmente, aplicar essa função ao EMV do parâmetro. Isso é válido sob certas condições, e é uma propriedade muito útil da Estimativa de Máxima Verossimilhança, pois nos permite estimar uma ampla variedade de quantidades de interesse de maneira eficaz.
%Podemos aplicar o EMV aos parâmetros e, em seguida, aplicar a função \(g\) aos resultados para obter o estimador do parâmetro \(\eta\). 
\end{block}
\pause
\begin{block}{}
\justifying
Em resumo, o Princípio da Invariância dos Estimadores de Verossimilhança estabelece que aplicar uma função a um estimador de EMV resulta no estimador de EMV para a mesma função aplicada aos parâmetros originais.
\end{block}
\end{frame}

\begin{frame}{Demonstração}
\begin{block}{}
\justifying
Suponha $g$ invertível. A verossimilhança de interesse é $L(g^{-1}(\eta)).$ Esta função é maximizada quando $g^{-1}(\eta)=\hat{\theta},$ isto é, tome $\hat{\eta}=g(\hat{\theta}).$
\end{block}
\end{frame}

\begin{frame}{Demonstração}
\begin{block}{}
\justifying
Suponha $g$ não invertível. Para cada valor de \(\eta\) dentro do alcance da função \(g\), definimos o conjunto (pré-imagem) \(g^{-1}(\eta) = \{\theta : g(\theta) = \eta\}\). O valor máximo de \(L\) ocorre em \(\hat{\theta}\), e o domínio de \(g\) é \(\Omega\), abrangendo \(\hat{\theta}\). Portanto, \(\hat{\theta}\) pertence a um destes conjuntos de pré-imagem, e na verdade, ele pode pertencer apenas a uma única pré-imagem. Para maximizar a função \(L(\eta)\), devemos selecionar \(\hat{\eta}\) de tal forma que \(g^{-1}(\hat{\eta})\) corresponda a essa pré-imagem única contendo \(\hat{\theta}\). Isso leva à equação \(\hat{\eta} = g(\hat{\theta})\).
\end{block}
\end{frame}

\begin{frame}{Teorema}
\begin{Teorema}\label{Teo3}
\justifying
Assuma $X_{1},\ldots,X_{n}$ satisfazendo as condições de regularidade $R0, R1$ e $R2$ com $\theta_{0}$ sendo o verdadeiro valor de $\theta.$ Além disso, assuma que $f(x,\theta)$ é diferenciável com relação a $\theta\in\Theta.$ Então, a equação 
\begin{align*}
    \dfrac{\partial L(\theta)}{\partial\theta}=0,~\text{ou, equivalentemente,}~\dfrac{\partial\ell(\theta)}{\partial\theta}=0,
\end{align*}
tem uma solução $\hat{\theta}_{n}$ tal que $\hat{\theta}_{n}\ConvP \theta_{0}.$
\end{Teorema}
\end{frame}

\begin{frame}{Demonstração}
\begin{block}{}
\justifying
Como $\theta_{0}$ é um ponto interior de $\Theta,$ existe $a>0$ tal que $(\theta_{0}-a,\theta_{0}+a)\subset\Theta.$ Defina, 
\begin{align*}
    S_{n}=\{L(\theta_{0},\vecX)>L(\theta_{0}+a,\vecX)\}\cap \{L(\theta_{0},\vecX)>L(\theta_{0}-a,\vecX)\}
\end{align*}
Provamos (Ver Teorema (\ref{Teo1})) que $\Lim P(S_{n})=1.$
\end{block}
\begin{block}{}
\justifying
Em $S_{n}$ temos a existência de um máximo local, digamos $\hat{\theta}_{n},$ ou seja, $\theta_{0}-a<\hat{\theta}_{n}<\theta_{0}+a$ e $\dfrac{\partial \ell(\theta)}{\partial\theta}|_{\theta=\hat{\theta}_{n}}=0.$ Portanto, 
\begin{align*}
    S_{n}&\subset \{|\hat{\theta}_{n}-\theta_{0}|<a\}\cap\Big\{\dfrac{\partial \ell(\theta)}{\partial\theta}=0\Big\}\\
    \Rightarrow P(S_{n})&\leq P\Big(\{|\hat{\theta}_{n}-\theta_{0}|<a\}\cap\Big\{\dfrac{\partial \ell(\theta)}{\partial\theta}=0\Big\}\Big)
\end{align*}
Observação: Essa etapa é importante porque estamos garantindo que o EMV existe e está próximo de 
$\hat{\theta}_{n}$ com alta probabilidade.
\end{block}
\end{frame}

\begin{frame}{Continuação da Demonstração}
\begin{block}{}
\begin{align*}
P(S_{n})&\leq P\Big(\{|\hat{\theta}_{n}-\theta_{0}|<a\}\cap\Big\{\dfrac{\partial \ell(\theta)}{\partial\theta}=0\Big\}\Big)\\
\Rightarrow \LimInf P(S_{n})&\leq \LimInf P\Big(\{|\hat{\theta}_{n}-\theta_{0}|<a\}\cap\Big\{\dfrac{\partial \ell(\theta)}{\partial\theta}=0\Big\}\Big)\\
&\Rightarrow \Lim P\Big(\{|\hat{\theta}_{n}-\theta_{0}|<a\}\cap\Big\{\dfrac{\partial \ell(\theta)}{\partial\theta}=0\Big\}\Big)=1
\end{align*}
pois $\LimInf P(S_{n})=1.$ Note que $P(\cdot)\geq 1\Rightarrow P(\cdot)=1.$
\end{block}
\end{frame}

\begin{frame}{Exercícios}
\begin{block}{\Home}
\justifying
Exercícios 6.1.1(letra a), 6.1.2, 6.1.4, 6.1.6,
6.1.9, 6.1.10 e 6.1.12
\nocite{hogg, casella2021statistical, bolfarine}
\end{block}
\end{frame}

\begin{frame}[allowframebreaks]
\frametitle{\bf Referências}
\printbibliography
\end{frame}


\end{document}

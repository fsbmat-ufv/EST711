\documentclass[12pt]{beamer}

\input{../Configuracoes/layout}

\title{Inferência Estatística II}
\author{Prof. Fernando de Souza Bastos\texorpdfstring{\\ fernando.bastos@ufv.br}{}}
\institute{Departamento de Estatística\texorpdfstring{\\ Programa de Pós-Graduação em Estatística Aplicada e Biometria}\texorpdfstring{\\ Universidade Federal de Viçosa}{}\texorpdfstring{\\ Campus UFV - Viçosa}{}}
\date{}
\newcommand\mytext{Aula 15}
\newcommand\mytextt{Fernando de Souza Bastos}
\newcommand\mytexttt{\url{https://est711.github.io/}}


\begin{document}
%\SweaveOpts{concordance=TRUE}

\frame{\titlepage}

\begin{frame}{}
\frametitle{\bf Sumário}
\tableofcontents
\end{frame}

\section{Razão de Verossimilhança Monótona}
\begin{frame}{Razão de Verossimilhança Monótona}
\begin{block}{}
\justifying
A Razão de Verossimilhança Monótona (RVM) está relacionada à comparação de dois modelos estatísticos por meio da razão de suas funções de verossimilhança. 
\end{block}
\pause
\begin{block}{}
	\justifying
	A razão de verossimilhança é definida como o quociente 
	
	\[
	\frac{L(\theta_0 | T(X))}{L(\theta_1 | T(X))}
	\]
	
	para dois valores de parâmetro \(\theta_0\) e \(\theta_1\). Dizemos que a razão de verossimilhança é \textbf{monótona} se, para quaisquer dois valores \(\theta_1 > \theta_0\), a razão de verossimilhança for uma função \textbf{monótona não-decrescente} em relação a estatística \(T(X)\).
\end{block}
%\begin{block}{}
%	\justifying
%	Suponha que tenhamos dois modelos estatísticos, \(M_0\) e \(M_1\), com funções de verossimilhança associadas \(L(\theta_0 | T(X))\) e \(L(\theta_1 | T(X))\), respectivamente, onde \(X\) representa uma amostra observada e \(T(X)\) é uma estatística específica resumindo as informações contidas na amostra. A Razão de Verossimilhança Monótona compara essas duas verossimilhanças de uma maneira especial.
%\end{block}
\end{frame}

\begin{frame}{Razão de Verossimilhança Monótona}
%\begin{block}{}
%\justifying
%A razão de verossimilhança é definida como o quociente 
%
%\[
%\frac{L(\theta_0 | T(X))}{L(\theta_1 | T(X))}
%\]
%
%para dois valores de parâmetro \(\theta_1\) e \(\theta_0\). Dizemos que a razão de verossimilhança é \textbf{monótona} se, para quaisquer dois valores \(\theta_1 > \theta_0\), a razão de verossimilhança for uma função \textbf{monótona não-decrescente} em relação a estatística \(T(X)\).
%\end{block}
%\pause
\begin{block}{}
\justifying
A monotonicidade aqui é uma propriedade importante, pois implica que, se um modelo é mais provável do que outro para uma dada estatística \(T(X)\), ele permanecerá mais provável à medida que a estatística \(T(X)\) aumenta. Isso é fundamental em testes de hipóteses e inferência estatística, pois garante uma ordem consistente de preferência entre os modelos em estudo.
\end{block}
\end{frame}

\begin{frame}{Razão de Verossimilhança Monótona}
\begin{definicao}
\justifying
Uma família de funções de densidade de probabilidade \(\{f_{\vec{X}}(\cdot; \theta), \theta \in \Theta\}\), \(\Theta \in \mathbb{R}\), é dita ter Razão de Verossimilhança Monótona (RVM) se existir uma estatística \(T = t(\vec{X})\) tal que, para todo \(\theta_1 > \theta_0\),

\[
\frac{L(\theta_0 \mid T(\vec{X}))}{L(\theta_1 \mid T(\vec{X}))}
\]

é uma função monótona (não decrescente ou não crescente) em \(t(\vec{x})\), para \(\vec{x} \in \{f(\vec{x}; \theta_0) > 0 \text{e} f(\vec{x}; \theta_1) > 0\}\), em que \(f_{\vec{X}}(\vec{x}; \theta_0) \neq f_{\vec{X}}(\vec{x}; \theta_1)\).

\end{definicao}
\end{frame}

\subsection{Exemplo 1}
\begin{frame}{Exemplo 1}
\vspace{-0.3cm}
\begin{block}{}
\justifying
Seja $X_1, \ldots, X_n$ uma amostra de $X \sim \text{Exp}(\theta)$. Segue que,
\[
\frac{L(\theta_0 | T(\tend{X}))}{L(\theta_1 | T(\tend{X}))} = \frac{{\displaystyle \prod_{i=1}^{n}} \theta_0}{{\displaystyle \prod_{i=1}^{n}} \theta_1} \exp\left(-\left(\frac{1}{\theta_1} - \frac{1}{\theta_0}\right)\sum_{i=1}^{n} x_i\right)
\]
\end{block}
\pause
\vspace{-0.3cm}
\begin{block}{}
\justifying
A função acima é monótona não decrescente em $t(\Vec{x}) = \Sumi x_i,$ logo, $\text{Exp}(\theta)$ tem Razão de Verossimilhança Monótona (RVM) não decrescente em $t(\Vec{x}) = \Sumi x_i$. De outro lado, $\text{Exp}(\theta)$ tem RVM não crescente em $t^{*}(\Vec{x}) = -\Sumi x_i$.
\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{}
\justifying
Seja \(X_1, \ldots, X_n\) uma amostra de \(X \sim U(0, \theta)\). Considere \(y_{n} = \max\{X_1, \ldots, X_n\}\),

\[
L(\vec{x}; \theta) = \frac{1}{\theta^n} 1_{(0, \theta)}(y_n)
\]

Assim, se \(\theta_0 < \theta_1\), temos que:

\[
\frac{L(\vec{x}; \theta_1)}{L(\vec{x}; \theta_0)} = \left(\frac{\theta_0}{\theta_1}\right)^n \frac{1_{(0, \theta_1)}(y_n)}{1_{(0, \theta_0)}(y_n)}
\]

\end{block}
\end{frame}

\begin{frame}{Exemplo 2}
\begin{block}{}
\justifying
Portanto, note que, $U(0, \theta)$ tem Razão de Verossimilhança Monótona (RVM) não decrescente em $y_n$ e,
\[
g(y_n) = \begin{cases} 
\left(\frac{\theta_0}{\theta_1}\right)^n, & \text{se } 0 < y_n < \theta_0 \\
\infty, & \text{se } \theta_0 \leq y_n < \theta_1
\end{cases}
\]
\end{block}
\end{frame}

\begin{frame}{Observação}
\begin{block}{Página 350 do Casella e Berger (Tradução)}
\justifying
Muitas famílias de distribuição comuns têm uma RVM. Por exemplo, a distribuição normal (Variância conhecida, média desconhecida), de Poisson, e a Binomial, todas têm. Na verdade, qualquer família exponencial regular com $f(t|\theta)=h(t)c(\theta)\exp{w(\theta)t}$ tem uma RVM se $w(\theta)$ for uma função não decrescente.
\end{block}
\end{frame}

\section{Teorema de Karlin-Rubin}
\begin{frame}{Teorema de Karlin-Rubin}
\vspace{-0.2cm}
\begin{block}{}
\justifying
Considere testar $H_{0}: \theta \leq \theta_0$ versus $H_{1}: \theta > \theta_0.$
Seja $L(\theta; \Vec{x})$ a função de verosimilhança de uma distribuição com espaço de parâmetros $\Theta$ e estatística suficiente $T = t(\Vec{x})$ para $\theta,$ tal que, para quaisquer $\theta_0$ e $\theta_1$ em $\Theta$ tais que $\theta_0 < \theta_1$, a razão de verosimilhança
\begin{align*}
\Lambda(\Vec{x}; \theta_0, \theta_1) &= \frac{L(\theta_0; \Vec{x})}{L(\theta_1; \Vec{x})}
\end{align*}
é uma RVM (Ou seja, é uma função monótona (não decrescente ou não crescente) em $t(x)$). Sob tais condições, para um apropriado valor $t_{0},$ 
\begin{align*}
    C=\{\Vec{x};T(\Vec{x})> t_{0}\} 
\end{align*}
é uma região crítica para um teste uniformemente mais poderoso para $H_{0}: \theta \leq \theta_0$ versus $H_{1}: \theta > \theta_0$ de tamanho $\alpha=P_{\theta_{0}}(T(\Vec{x})> t_{0})$.
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{Observação:}
\justifying
Sob as condições do teorema anterior podemos testar $H_{0}: \theta \geq \theta_0$ versus $H_{1}: \theta < \theta_0.$ Nesse caso, 
\begin{align*}
    C=\{\Vec{x};T(\Vec{x})< t_{0}\} 
\end{align*}
é uma região crítica para um teste uniformemente mais poderoso para $H_{0}: \theta \geq \theta_0$ versus $H_{1}: \theta < \theta_0$ de tamanho $\alpha=P_{\theta_{0}}(T(\Vec{x})< t_{0})$.
\end{block}
\end{frame}

\subsection{Exemplo 1}
\begin{frame}{}
\begin{block}{}
\justifying
Considere \seqX~Poisson$(\theta).$ Encontre um TUMP de nível $\alpha$ para testar 
\begin{align*}
    H_{0}:\theta\leq \theta_{0}~\text{contra}~H_{1}:\theta> \theta_{0}
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
Sabemos que $T(\Vec{X})=\Sumi X_{i}$ é uma estatística suficiente para $\theta$ e que a distribuição de $T(\Vec{X})=\Sumi X_{i}$ é Poisson$(n\theta).$ Logo, 
\begin{align*}
    f(t;\theta)=\dfrac{e^{(-n\theta)}(n\theta)^{t}}{t!},~t=0,1,2,\cdots
\end{align*}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Considere $0<\theta_{1}<\theta_{2}<\infty$ e
\begin{align*}
    \dfrac{f(t;\theta_{2})}{f(t;\theta_{1})}=e^{-n(\theta_{2}-\theta_{1})}\left(\dfrac{\theta_{2}}{\theta_{1}}\right)^{t},
\end{align*}
está razão é uma RVM de $t,$ uma vez que $\theta_{1}<\theta_{2}.$
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Logo, a família Poisson tem a propriedade de RVM. Pelo teorema de Karlin-Rubin, o teste que rejeita $H_{0}$ para toda amostra $\Vec{X}$ tal que $\Sumi X_{i}>t_{0}$ é um teste uniformemente mais poderoso de tamanho $\alpha=P_{\theta_{0}}(\Sumi X_{i}>t_{0}).$
\end{block}
\end{frame}


\begin{frame}{}
\begin{block}{}
\justifying
Suponha 
\begin{align*}
    H_{0}&:\theta\leq 1~\text{contra}~H_{1}:\theta> 1\\
    n&=100\\
    \alpha&=0.05
\end{align*}
Segue que $\Sumi X_{i}\sim~$Poisson$(100\theta),$ sob $H_{0}, \Sumi X_{i}\sim~$Poisson$(100).$
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
No software R, obtemos $t_{0}=117$ e $P_{\theta_{0}}(\Sumi X_{i}>t_{0})\approx 0,043\leq \alpha.$ Logo, o teste que rejeita $H_{0}$ para toda amostra de tamanho $n=100$ quando $\Sumi X_{i}>117$ é um TUMP de nível $0.05.$ O tamanho do teste é $P_{\theta_{0}}(\Sumi X_{i}>117)\approx 0,043.$
\end{block}
\end{frame}

\subsection{Exemplo 2}
\begin{frame}{}
\begin{block}{}
\justifying
Seja \seqX~ uma amostra aleatória de uma distribuição exponencial$(\theta).$ Encontre um TUMP de 
\begin{align*}
    H_{0}:\theta\geq \theta_{0}~\text{contra}~H_{1}:\theta< \theta_{0}
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
Sabemos que $T(\Vec{X})=\Sumi X_{i}$ é uma estatística suficiente para $\theta$ e que a distribuição de $T(\Vec{X})=\Sumi X_{i}$ é Gamma$(n,\theta).$ Logo, para $0<\theta_{1}<\theta_{2}<\infty$
\begin{align*}
    \dfrac{f(t;\theta_{2})}{f(t;\theta_{1})}=\left(\dfrac{\theta_{1}}{\theta_{2}}\right)e^{-t\left(\frac{1}{\theta_{2}}-\frac{1}{\theta_{1}}\right)},~\frac{1}{\theta_{2}}-\frac{1}{\theta_{1}}<0. 
\end{align*}
Dessa forma, temos uma RVM de $t.$ Logo, a família gamma tem a propriedade RVM. 
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Pelo teorema de Karlin-Rubin, o teste que rejeita $H_{0}$ para toda amostra $\Vec{X}$ tal que $\Sumi X_{i}<3$ é um teste uniformemente mais poderoso de tamanho $\alpha=P_{\theta_{0}}(\Sumi X_{i}<t_{0}).$
\end{block}
\pause
\begin{block}{}
\justifying
Considere, por exemplo, 
\begin{align*}
    H_{0}&:\theta\geq 3~\text{contra}~H_{1}:\theta< 3\\
    n&=5\\
    \alpha&=0.05
\end{align*}
Segue que $\Sumi X_{i}\sim~$Gamma$(5,\theta),$ sob $H_{0}, \Sumi X_{i}\sim~$Gamma$(5,3).$
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
    No software R, obtemos $t_{0}=5.91$ e $P_{\theta_{0}}(\Sumi X_{i}>t_{0})\approx 0,05.$ Logo, o teste que rejeita $H_{0}$ para toda amostra de tamanho $n=5$ quando $\Sumi X_{i}<5,91$ é um TUMP de tamanho $0.05.$ 
\end{block}
\nocite{hogg, casella2021statistical}
\end{frame}

%\begin{frame}{\Home}
%\begin{block}{}
%\justifying

%\begin{itemize}
%    \item \textbf{Exercícios da seção 8.2:} 1,3,5,6,11,13.
%\end{itemize}
%\end{block}
%
%\end{frame}

\begin{frame}[allowframebreaks]
\frametitle{\bf Referências}
\printbibliography
\end{frame}


\end{document}


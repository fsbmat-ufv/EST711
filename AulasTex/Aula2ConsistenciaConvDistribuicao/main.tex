
\documentclass[12pt]{beamer}

\input{../Configuracoes/layout}
\setLayoutColor{2} % Escolhe a cor (1, 2 ou 3)




\title{Inferência Estatística II}
\author{Prof. Fernando de Souza Bastos\texorpdfstring{\\ fernando.bastos@ufv.br}{}}
\institute{Departamento de Estatística\texorpdfstring{\\ Programa de Pós-Graduação em Estatística Aplicada e Biometria}\texorpdfstring{\\ Universidade Federal de Viçosa}{}\texorpdfstring{\\ Campus UFV - Viçosa}{}}
\date{}
\newcommand\mytext{Aula 2}
\newcommand\mytextt{Fernando de Souza Bastos}
\newcommand\mytexttt{\url{https://est711.github.io/}}


\begin{document}
%\SweaveOpts{concordance=TRUE}

\frame{\titlepage}

\begin{frame}{}
\frametitle{\bf Sumário}
\tableofcontents
\end{frame}

\section{Consistência}
\begin{frame}{Consistência}
%\begin{block}{}
\begin{definicao}
\justifying
 Seja $X$ uma variável aleatória com função de distribuição acumulada $F(x, \theta)$, $\theta \in \mathcal{A}\subseteq \Omega$. Seja $X_1, \ldots, X_{n}$ uma amostra da distribuição de $X$ e seja $T_{n}$ uma estatística $(T_{n}=T(X_1, \ldots, X_{n}))$. Dizemos que $T_{n}$ é um estimador consistente para $\theta$ se $T_{n} \xrightarrow{P} \theta$.
\end{definicao}    
%\end{block}
\end{frame}

\begin{frame}{Exemplo}
\begin{block}{}
\justifying
Sejam $X_{1}, \ldots, X_{n},\ldots$ uma sequência de variáveis aleatórias iid de uma distribuição com média finita $\mu$ e variância $\sigma^{2}<+\infty$, então, pela Lei Fraca dos Grandes Números, temos que, $\Bar{X_{n}}=\dfrac{\Sumi X_{i}}{n}\ConvP \mu.$ Ou seja, $\Bar{X_{n}}$ é um estimador consistente de $\mu$.
\end{block}
\end{frame}

\begin{frame}{Exemplo}
\begin{block}{}
\justifying
Sejam $X_1, \ldots, X_{n}$ uma amostra aleatória de uma distribuição com média $\mu$ e variância $\sigma^{2}<+\infty$. Então $S^2_{n}$ é um estimador consistente para $\sigma^{2}.$%Suponha que $E[X^{4}_{1}] < +\infty$, de tal forma que $Var(S^{2}) < +\infty$. 
\begin{align*}
S^2_{n} &= \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X}_{n})^2 \\
&=\frac{1}{n-1} \left(\sum_{i=1}^n X_{i}^{2} - n\overline{X}_{n}^{2}\right)\\
&= \frac{n}{n-1} \left(\frac{1}{n}\sum_{i=1}^n X^{2}_i - \overline{X}^{2}_{n}\right) \\
&\xrightarrow{P} 1 \cdot [E(X^2_1) - \mu^2] = \sigma^2.
\end{align*}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Portanto, a variância da amostra é um estimador consistente de $\sigma^2$. A partir da discussão acima, temos imediatamente que $S_{n} \xrightarrow{P} \sigma$; ou seja, o desvio padrão da amostra é um estimador consistente do desvio padrão populacional. Vejam estes exemplos anteriores na prática, \href{https://est711.shinyapps.io/ConvergenciaProbabilidade/}{Clique aqui!}.
\end{block}
\end{frame}

\begin{frame}{Exemplo}
\vspace{-0.3cm}
\begin{block}{}
\justifying
Considere $X_{i}\overset{\text{iid}}{\sim} U(0,\theta),~i=1,2,\ldots,n,$ e $Y_{n}=max\{X_{1}, \ldots, X_{n}\}.$ Seja $\varepsilon>0,$ segue que:
\begin{align*}
    P(|Y_{n}-\theta|\geq \varepsilon)&=P(\theta-Y_{n}\geq \varepsilon)\\
    &=P(Y_{n}\leq \theta-\varepsilon).
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
Se $\theta-\varepsilon\leq 0,$ então $P(Y_{n}\leq \theta-\varepsilon)=0,$ pois $0\leq Y_{n}\leq \theta,$ com $P(0\leq Y_{n}\leq \theta)=1.$
\end{block}
\pause
\begin{block}{}
\justifying
Se $0<\varepsilon<\theta$ então,
\begin{align*}
P(|Y_{n}-\theta|\geq \varepsilon)&=P(Y_{n}\leq \theta- \varepsilon)=F_{Y_{n}}(\theta-\varepsilon)=\Big(\dfrac{\theta-\varepsilon}{\theta}\Big)^{n}\xrightarrow[n\rightarrow\infty]{} 0
\end{align*}
Ou seja, $Y_{n} \xrightarrow{P} \theta.$ Logo, $Y_{n}$ é um estimador consistente para $\theta.$
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{\Home}
\justifying
Exercícios 2.8.18, 5.1.2, 5.1.3, 5.1.7 e 5.1.9
\end{block}
\end{frame}

\section{Convergência em Distribuição}
\begin{frame}{Convergência em Distribuição}
\begin{definicao}
\justifying
Seja $\{X_{n}\}_{n\geq 1}$ uma sequência de variáveis aleatórias com função de distribuição $F_{X_{n}},~n\geq 1.$ Seja $X$ uma variável aleatória com função de distribuição $F_{X}.$ Seja $C(F_{X})$ o conjunto de todos os pontos de continuidade de $F_{X}$. Dizemos que $X_{n}$ converge em distribuição para $X$ se,
$$\lim_{{n \to \infty}} F_{X_{n}}(x) = F_X(x), ~\forall x \in C(F_X).$$ Denotamos essa convergência por $X_{n} \overset{D}{\rightarrow} X$ ou $X_{n} \overset{\mathcal{L}}{\rightarrow} X.$
\end{definicao}
\pause
\begin{block}{}
	À medida que o tamanho da amostra aumenta, a distribuição das médias amostrais se aproxima da distribuição normal, veja isso acontecendo na prática, \href{https://est711.shinyapps.io/ConvergenciaProbabilidade/}{Clique aqui!}.
\end{block}

\end{frame}

\begin{frame}{Exemplo}
\begin{block}{}
\justifying
\begin{align*}
    P\Big(X_{n}=\dfrac{1}{n}\Big)=1, \forall n\geq 1,~P(X=0)=1, \mathcal{C}(F_{X}(x))=\{x\in\R; x\neq 0\}
\end{align*}
\end{block}
\begin{block}{}
\begin{figure}%
    \centering
    \subfloat[\centering $P\Big(X_{n}=\dfrac{1}{n}\Big)=1$]{{\begin{tikzpicture}[scale=0.75]
%plano cartesiano
\draw[->] (-2,0) -- (3,0) node[right]{$x$};
\draw[->] (0,-.5) -- (0,2) node[above]{$F_{X_{n}}(x)$};
%Fun ̧c~ao
\draw[line width=2pt,domain=-2:0.96] plot
(\x,0);
\draw[fill=white] (1,0) circle (2pt);
\fill (1,1) circle (2pt);
\draw[line width=1pt,domain=1:2.5] plot
(\x,1);
% ́Indices
\draw[dashed] (1,1) -- (1,0) node[below,scale=.7] {$\dfrac{1}{n}$};
\node[scale=.7] at (-0.2,1) {$1$};
\end{tikzpicture} }}%
    \qquad
    \subfloat[\centering $P(X=0)=1$]{{\begin{tikzpicture}[scale=0.75]
%plano cartesiano
\draw[->] (-2,0) -- (3,0) node[right]{$x$};
\draw[->] (0,-.5) -- (0,2) node[above]{$F_{X}(x)$};
%Fun ̧c~ao
\draw[line width=2pt,domain=-2:-0.04] plot
(\x,0);
\draw[fill=white] (0,0) circle (2pt);
\fill (0,1) circle (2pt);
\draw[line width=1pt,domain=0:2.5] plot
(\x,1);
% ́Indices
\draw[dashed] (0,1) -- (0,0) node[below,scale=.7] {$0$};
\node[scale=.7] at (-0.2,1) {$1$};
\end{tikzpicture}}}%
    \caption{${\displaystyle \lim_{n\rightarrow+\infty}}F_{X_{n}}(x)=F_{X}(x),~\forall x\neq 0,~\text{ou seja}~X_{n} \overset{D}{\rightarrow} X$}%
    \label{fig:example}%
\end{figure}
\end{block}
\end{frame}

\begin{frame}{Exemplo 2 (Convergência em Distribuição não Implica Convergência em Probabilidade)}
\begin{block}{}
\justifying
Seja $X$ uma variável aleatória contínua simétrica em torno do zero (ou seja, se $f$ denota sua densidade, então $f(x) = f(-x), \forall x\in \R$. Neste caso, $X$ e $-X$ tem a mesma distribuição (Verifiquem!). Defina a sequência de variáveis aleatórias $X_{n}$ como:
$X_{n} = \begin{cases} 
X, & \text{se $n$ é par} \\ 
-X, & \text{se $n$ é impar} 
\end{cases}$
\end{block}
\pause
\begin{block}{}
\justifying
É fácil ver que $F_{X_{n}}(x)=F_{X}(x).$ Logo, $X_{n} \overset{D}{\rightarrow} X.$ Porém, $X_{n} \overset{P}{\cancel{\rightarrow}} X,$ pois 
$P(|X_{n}-X|\geq\varepsilon) = \begin{cases} 
0, & \text{se $n$ é par} \\ 
P(2|X|\geq \varepsilon), & \text{se $n$ é impar}
\end{cases}$
\end{block}
\end{frame}

\begin{frame}{Exemplo 3}
\begin{block}{}
\justifying
Seja $T_{n}$ uma variável aleatória com distribuição t-Student com $n$ graus de liberdade, ou seja, a densidade de $T_{n}$ é dada por:
\begin{align*}
    f_{T_{n}}(y)=\dfrac{\Gamma\Big(\dfrac{n+1}{2}\Big)}{\sqrt{n\pi}\Gamma\Big(\dfrac{n}{2}\Big)}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}},~y\in \R
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
Temos que,
\begin{align*}
\lim_{n\rightarrow+\infty}F_{T_{n}}(t)=\lim_{n\rightarrow+\infty}\int_{-\infty}^{t}\dfrac{\Gamma\Big(\dfrac{n+1}{2}\Big)}{\sqrt{n\pi}\Gamma\Big(\dfrac{n}{2}\Big)}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}dy
\end{align*}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\begin{align*}
\lim_{n\rightarrow+\infty}F_{T_{n}}(t)&=\lim_{n\rightarrow+\infty}\int_{-\infty}^{t}\dfrac{\Gamma\Big(\dfrac{n+1}{2}\Big)}{\sqrt{n\pi}\Gamma\Big(\dfrac{n}{2}\Big)}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}dy\\
\underset{\mathclap{\substack{\xuparrow[30pt]\\ \text{Teorema da}\\ \text{Convergência Dominada}}}}{}&=\int_{-\infty}^{t}\lim_{n\rightarrow+\infty}\dfrac{\Gamma\Big(\dfrac{n+1}{2}\Big)}{\sqrt{n\pi}\Gamma\Big(\dfrac{n}{2}\Big)}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}dy\\
&=\star\star
\end{align*}

\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
Considere a seguinte aproximação de Stirling (Conhecida como fórmula de Stirling): $$\Gamma(t+1)\approx \sqrt{2\pi t}\Big(\dfrac{t}{e}\Big)^{t}$$
Ou seja, $${\displaystyle \lim_{t\rightarrow+\infty} \dfrac{\Gamma(t+1)}{\sqrt{2t\pi}\Big(\dfrac{t}{e}\Big)^{t}}}=1$$
\end{block}
\pause
\begin{block}{}
Logo,
{\scriptsize
\begin{align*}
\lim_{n\rightarrow+\infty}\dfrac{\Gamma\Big(\dfrac{n+1}{2}\Big)}{\sqrt{n\pi}\Gamma\Big(\dfrac{n}{2}\Big)}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}&=
\lim_{n\rightarrow+\infty}
\dfrac{\sqrt{2\pi}\Big(\frac{n-1}{2}\Big)^{\frac{n-1}{2}+\frac{1}{2}}e^{-(\frac{n-1}{2})}}{\sqrt{n}\sqrt{2\pi}\Big(\dfrac{n-2}{2}\Big)^{\frac{n-2}{2}+\frac{1}{2}}e^{-(\frac{n-2}{2})}}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}\\
&=\star ~(\text{t da fórmula de Stirling será}~\frac{n-1}{2})
\end{align*}
}
\end{block}
\end{frame}

\begin{frame}{}
\begin{block}{}
\justifying
\begin{align*}
    \star&=\dfrac{e^{-\frac{1}{2}}}{\sqrt{2\pi}}{\displaystyle \lim_{n\rightarrow\infty}\dfrac{(n-1)^{\frac{n}{2}}}{(n-2)^{\frac{n}{2}}(n-2)^{-\frac{1}{2}}}}\dfrac{1}{\sqrt{n}}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{n+1}{2}}}\\
    &=\dfrac{e^{-\frac{1}{2}}}{\sqrt{2\pi}}{\displaystyle \lim_{n\rightarrow\infty}\dfrac{(1-\frac{1}{n})^{\frac{n}{2}}}{(1-\frac{2}{n})^{\frac{n}{2}}}}\sqrt{\dfrac{n-2}{n}}\dfrac{1}{\Big(1+\dfrac{\frac{y^{2}}{2}}{\frac{n}{2}}\Big)^{\frac{n}{2}}}\dfrac{1}{\Big(1+\dfrac{y^{2}}{n}\Big)^{\frac{1}{2}}}\\
    &=\dfrac{e^{-\frac{1}{2}}}{\sqrt{2\pi}}e^{-\frac{y^{2}}{2}}e^{\frac{1}{2}}=\dfrac{e^{-\frac{y^{2}}{2}}}{\sqrt{2\pi}}
\end{align*}
\end{block}
\pause
\begin{block}{}
\justifying
Portanto, substituindo em $\star\star,$ temos 
\begin{align*}
\lim_{n\rightarrow+\infty}F_{T_{n}}(t)&=\int_{-\infty}^{t}\dfrac{e^{-\frac{y^{2}}{2}}}{\sqrt{2\pi}}dy\Rightarrow T_{n} \overset{D}{\rightarrow} N(0,1).
\end{align*}
\nocite{hogg}
\end{block}
\end{frame}



\begin{frame}[allowframebreaks]
\frametitle{\bf Referências}
\printbibliography
\end{frame}


\end{document}
